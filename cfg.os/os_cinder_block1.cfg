#
# This is to setup OpenStack Cinder on the block1 node
#
# ref: https://docs.openstack.org/ocata/install-guide-ubuntu
#
# Prerequisites:
#   - The basic IP network should be up running; and
#   - The ssh connection should be configured with out passwd typed
#     e.g., echo "stack ALL=(ALL) NOPASSWD: ALL" | tee -a /etc/sudoers
#
# Note:
#   - If the State is down for cinder-volume in "volume service list", the big
#     NTP time gap will be likely cause if configuration are correct.

#
# The global variables for this project
#
OS_CONTROLLER_IF_MANAGEMENT := 10.0.0.11/24

OS_CONTROLLER_IF_PROVIDER_NAME := enp0s25
OS_COMPUTE1_IF_PROVIDER_NAME := enp3s0f1

OS_NET := 10.0.0.0/24
OS_CONTROLLER_NAME := controller
OS_CONTROLLER_IP := 10.0.0.11
OS_COMPUTE1_NODE_NAME := compute1
OS_COMPUTE1_NODE_IP := 10.0.0.31
OS_BLOCK1_NODE_NAME := block1
OS_BLOCK1_NODE_IP := 10.0.0.41
OS_OBJECT1_NODE_NAME := object1
OS_OBJECT1_NODE_IP := 10.0.0.51
OS_OBJECT2_NODE_NAME := object2
OS_OBJECT2_NODE_IP := 10.0.0.52

# The stable ntp server either name or ip:
OS_NTP_SERVER := 10.121.52.95

OS_BLOCK1_VOLUME_DEV_CINDER := /dev/sda6

OS_ADMIN_CLI := export no_proxy=localhost,127.0.0.1,controller,block1,compute1; openstack --os-auth-url http://controller:35357/v3 --os-project-domain-name Default --os-user-domain-name Default --os-project-name admin --os-identity-api-version=3 --os-image-api-version=2 --os-username admin --os-password=stack

OS_DEMO_CLI := export no_proxy=localhost,127.0.0.1,controller,block1,compute1; openstack --os-auth-url http://controller:5000/v3 --os-project-domain-name default --os-user-domain-name default --os-identity-api-version=3 --os-image-api-version=2 --os-project-name demo --os-username demo --os-password=demo

#
# Ubuntu routine package update
#

STEP_000.CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo pwd"
STEP_000.description:= Root privilege required for this setup


#
# Install and configure Nova on the block1 node
#

STEP_961.CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo apt install lvm2 cinder-volume -y"
STEP_961.description := Install the supporting utility package of lvm2.

STEP_967.CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo pvcreate $::TQ_CONFIG{OS_BLOCK1_VOLUME_DEV_CINDER}"; pwd
STEP_967.description := Create the LVM physcial volume.

STEP_968.CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo vgcreate cinder-volumes $::TQ_CONFIG{OS_BLOCK1_VOLUME_DEV_CINDER}"; pwd
STEP_968.description := Create the LVM volume group.


#
# Install and configure Cinder-volume
#
STEP_970_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::^\[database\]::\\n\[database\]\n::$::"
STEP_970.description := Add db section if misses for Cinder service

STEP_971_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::^\[keystone_authtoken\]::\\n\[keystone_authtoken\]\n::$::"
STEP_971.description := Add keystone section if misses for Cinder service

STEP_972_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo sed -i '/^connection\s*=\s*sqlite:/I d' /etc/cinder/cinder.conf"
STEP_972.description := Remove connection as block1 does not directly access db

STEP_973_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::#MYEX ID CINDER DB::\\n#MYEX ID CINDER DB\nconnection = mysql+pymysql://cinder:stack@controller/cinder\n::/^\[database\]/::"
STEP_973.description := Configure oslo section

STEP_974_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::#MYEX ID CINDER DEFAULT::\\n#MYEX ID CINDER DEFAULT\ntransport_url = rabbit://openstack:stack@controller\nmy_ip = $::TQ_CONFIG{OS_BLOCK1_NODE_IP}\nauth_strategy = keystone\nenabled_backends = lvm\nglance_api_servers = http://controller:9292\n::/^\[DEFAULT\]/::"
STEP_974.description := Configure message queue access

STEP_975_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::#MYEX ID CINDER AUTH::\\n#MYEX ID CINDER AUTH\nauth_uri = http://controller:5000\nauth_url = http://controller:35357\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = stack\n::/^\[keystone_authtoken\]/::"
STEP_975.description := Configure IS access for nova api


STEP_976_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::^\[lvm\]::\\n\[lvm\]\n::$::"
STEP_976.description := Add lvm section if misses for Cinder service

STEP_977_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::^\[oslo_concurrency\]::\\n\[oslo_concurrency\]\n::$::"
STEP_977.description := Add oslo section if misses for Cinder service


STEP_978_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::#MYEX ID CINDER LVM::\\n#MYEX ID CINDER LVM\nvolume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver\nvolume_group = cinder-volumes\niscsi_protocol = iscsi\niscsi_helper = tgtadm\n::/^\[lvm\]/::"
STEP_978.description := Configure LVM section

STEP_979_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/cinder/cinder.conf::#MYEX ID CINDER OSLO::\\n#MYEX ID CINDER OSLO\nlock_path = \/var\/lib\/cinder\/tmp\n::/^\[oslo_concurrency\]/::"
STEP_979.description := Configure oslo section


#
# Verify block1 node into the cell db on the controller node
#

STEP_980_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "MYEX_UPDATE_FILE::/etc/sudoers::#MYEX ID CINDER::\\n#MYEX ID CINDER\ncinder ALL=(ALL) NOPASSWD: ALL\n::$::"
STEP_980.description := Configure user cinder into group of sudoers

STEP_981_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo service tgt restart"
STEP_981.description := Restart tgt

STEP_982_CMD := ssh $::TQ_CONFIG{OS_BLOCK1_NODE_IP} "sudo service cinder-volume restart"
STEP_982.description := Restart the Block storage service

STEP_989_CMD := $::TQ_CONFIG{OS_ADMIN_CLI} volume service list; pwd
STEP_989.description := Confirm there are columes in the database


